{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning pretrained Herbert model for task of Named Entity Detection\n",
    "Named Entity Detection is task similar to more popular Named Entity Recognizing.\n",
    "Detection means we are trying to find Named Entity occurences, but we don't need to distinguish between different Named Entity classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Install pre-requirements\n",
    "We will use *huggingface* workflow with *pytorch* framework to train model and to operate sets we use 🤗 *datasets*.\n",
    "We also use *sklearn* for metrics and *tensorboard* for logging training progress.\n",
    "To install *pytorch* the best way is to reference official installation page in *pytorch* website: https://pytorch.org/get-started/locally/.\n",
    "For 🤗 transformers refer to: https://huggingface.co/docs/transformers/installation\n",
    "For 🤗 datasets: https://huggingface.co/docs/datasets/installation\n",
    "For sklearn: https://scikit-learn.org/stable/install.html\n",
    "For tensorboard: https://pypi.org/project/tensorboard/ for pypi package or https://anaconda.org/conda-forge/tensorboard for conda.\n",
    "\n",
    "\n",
    "##### *Note*\n",
    "*If possible choose combination which will allow hardware acceleration, e.g. cuda if you have compatible nvidia-gpu.*\n",
    "\n",
    "Below are commands to install within current jupiter environment.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install torch --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip install transformers datasets\n",
    "!pip install scikit-learn\n",
    "!pip install tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's set up constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cache_dir = 'D:/cache/huggingface'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Loading pretrained model\n",
    "As focus for this model is to work with NED task on Polish data, we need to use pretrained model which is either multilingual or trained on Polish data.\n",
    "Currently, one of the best pretrained language models for Polish language is HerBERT. You can find more information in its model card: https://huggingface.co/allegro/herbert-base-cased\n",
    "HerBERT is BERT based language model. We will train it to perform Token Classification task, so we should use *BertForTokenClassification* class from *transformers*.\n",
    "\n",
    "We will try to predict 3 classes in *IOB* format. Also, we should set up dropout to prevent overfitting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.sso.sso_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.sso.sso_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, HerbertTokenizerFast\n",
    "\n",
    "name = \"allegro/herbert-base-cased\"\n",
    "\n",
    "\n",
    "tokenizer = HerbertTokenizerFast.from_pretrained(\n",
    "    name, cache_dir=cache_dir\n",
    ")\n",
    "model: BertForTokenClassification = BertForTokenClassification.from_pretrained(\n",
    "    name, cache_dir=cache_dir, num_labels=3,\n",
    "    attention_probs_dropout_prob=0.3,\n",
    "    hidden_dropout_prob=0.3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use scheduled training starting with training auxiliary layers of classifier first. During training we will extend gradient updates down into language models weights. This way we can finetune not only classifier but also language model - still using GPU with relatively small 4GB VRAM."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models classifier:  Linear(in_features=768, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# We can check now size of our classifier\n",
    "print(\"Models classifier: \", model.classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Preparing dataset\n",
    "Let's start with downloading Polish NER dataset. Dataset we will be using is called *kpwr-ner* we can check more information about it, on its dataset card on huggingface website: https://huggingface.co/datasets/clarin-pl/kpwr-ner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset kpwrner (D:/cache/huggingface\\clarin-pl___kpwrner\\default\\0.0.0\\001e3d471298007e8412e3a6ccc06bec000dec1bce0cf8e0ba7e5b7e105b1342)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e65025ab2304f92a9a664a47c37acf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "kpwr_set = load_dataset(\"clarin-pl/kpwr-ner\", cache_dir=cache_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each token is tagged in IOB format.\n",
    "*O* means *Other* token - outside of phrase.\n",
    "*B-* means *Beginning* - first token of phrase.\n",
    "*I-* means *Inner* - second or subsequent token in phrase.\n",
    "Tokens *B-* and *I-* also contain information about class of given phrase for example: *B-nam_liv_person*  and *I-nam_liv_person* for name of person, or *B-nam_loc_gpe_city* and *I-nam_loc_gpe_city* for name of the geographical location - city to be exact, etc.\n",
    "We need to change those tokens into 3 tokens that we want to predict:\n",
    "*O* - token will be indexed as *0*\n",
    "*B* - token will be indexed as *1*\n",
    "*I* - token will be indexed as *2*\n",
    "As HerBERT does not use word tokenizer, but sub-word tokenizer - we will also encounter special token tag *-100*, which means given token is a subsequent sub-word token not first sub-word in word representation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/14 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "754e93221efb4fcfba83affc261e4f95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at D:/cache/huggingface\\clarin-pl___kpwrner\\default\\0.0.0\\001e3d471298007e8412e3a6ccc06bec000dec1bce0cf8e0ba7e5b7e105b1342\\cache-f075577aa7c293af.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "# Casting NER to NED format\n",
    "def cast_ner_to_ned(tag_i):\n",
    "    tag = kpwr_set['train'].features['ner'].feature.int2str(tag_i)\n",
    "    if 'b' == tag[0].lower():\n",
    "        return 1\n",
    "    if 'i' == tag[0].lower():\n",
    "        return 2\n",
    "\n",
    "    assert tag.lower() == 'o'\n",
    "    return 0\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner\"]):\n",
    "        # Map tokens to their respective word.\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # Only label the first token of a given word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(cast_ner_to_ned(label[word_idx]))\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_kwpr = kpwr_set.map(tokenize_and_align_labels, batched=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from transformers import TrainingArguments, Trainer, SchedulerType, IntervalStrategy\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    ignore_index = labels == -100\n",
    "    other_pred = np.logical_or(predictions == 0, ignore_index)\n",
    "    other_label = np.logical_or(labels == 0, ignore_index)\n",
    "    hit_others = np.logical_not(np.logical_and(other_label, other_pred))\n",
    "    acc = accuracy_score(labels[hit_others], predictions[hit_others])\n",
    "\n",
    "    f1 = f1_score(labels[hit_others], predictions[hit_others], average='macro')\n",
    "\n",
    "    return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "\n",
    "batch_size = 20\n",
    "save_path = 'D:/models/ned'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=save_path,\n",
    "    evaluation_strategy=IntervalStrategy.EPOCH,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size*2,\n",
    "    num_train_epochs=25,\n",
    "    lr_scheduler_type=SchedulerType.LINEAR,\n",
    "    do_eval=True,\n",
    "    do_predict=True,\n",
    "    save_steps=200,\n",
    "    logging_steps=100,\n",
    "    learning_rate=1\n",
    ")\n",
    "\n",
    "model_size = 512\n",
    "warmup = 1000\n",
    "\n",
    "\n",
    "def lambda_lr(step):\n",
    "    step += 1\n",
    "    if step == 2600:\n",
    "        print(\"Training layer 11.\")\n",
    "        for param in model.bert.encoder.layer[11].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if step == 5400:\n",
    "        print(\"Training layer 10.\")\n",
    "        for param in model.bert.encoder.layer[10].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if step == 7600:\n",
    "        print(\"Training layer 9.\")\n",
    "        for param in model.bert.encoder.layer[9].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if step == 10000:\n",
    "        print(\"Training layer 8.\")\n",
    "        for param in model.bert.encoder.layer[9].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model_size**(-0.5)*(min(step ** (-0.5), step * warmup ** (-1.5)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are adding a <class 'transformers.integrations.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "NotebookProgressCallback\n"
     ]
    }
   ],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def create_scheduler(\n",
    "            self, num_training_steps: int,\n",
    "            optimizer: torch.optim.Optimizer = None\n",
    "    ):\n",
    "        optimizer = self.optimizer if optimizer is None else optimizer\n",
    "        self.lr_scheduler = LambdaLR(optimizer, lambda_lr, -1)\n",
    "        return self.lr_scheduler\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_kwpr[\"train\"],\n",
    "    eval_dataset=tokenized_kwpr[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\n",
    "trainer.add_callback(TensorBoardCallback())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running training *****\n",
      "  Num examples = 13959\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 20\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 20\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17450\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='17450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    2/17450 : < :, Epoch 0.00/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/models/ned\\checkpoint-200\n",
      "Configuration saved in D:/models/ned\\checkpoint-200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-400\n",
      "Configuration saved in D:/models/ned\\checkpoint-400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-600\n",
      "Configuration saved in D:/models/ned\\checkpoint-600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-600\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-800\n",
      "Configuration saved in D:/models/ned\\checkpoint-800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-1000\n",
      "Configuration saved in D:/models/ned\\checkpoint-1000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-1200\n",
      "Configuration saved in D:/models/ned\\checkpoint-1200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-1200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-1200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-1200\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-1400\n",
      "Configuration saved in D:/models/ned\\checkpoint-1400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-1400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-1400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-1400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-1600\n",
      "Configuration saved in D:/models/ned\\checkpoint-1600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-1600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-1600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-1600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-1800\n",
      "Configuration saved in D:/models/ned\\checkpoint-1800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-1800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-1800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-1800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-2000\n",
      "Configuration saved in D:/models/ned\\checkpoint-2000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-2000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-2200\n",
      "Configuration saved in D:/models/ned\\checkpoint-2200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-2200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-2200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-2200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-2400\n",
      "Configuration saved in D:/models/ned\\checkpoint-2400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-2400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-2400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-2400\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer 11.\n",
      "Training layer 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/models/ned\\checkpoint-2600\n",
      "Configuration saved in D:/models/ned\\checkpoint-2600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-2600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-2600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-2600\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-2800\n",
      "Configuration saved in D:/models/ned\\checkpoint-2800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-2800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-2800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-2800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-3000\n",
      "Configuration saved in D:/models/ned\\checkpoint-3000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-3000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-3200\n",
      "Configuration saved in D:/models/ned\\checkpoint-3200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-3200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-3200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-3200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-3400\n",
      "Configuration saved in D:/models/ned\\checkpoint-3400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-3400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-3400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-3400\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-3600\n",
      "Configuration saved in D:/models/ned\\checkpoint-3600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-3600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-3600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-3600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-3800\n",
      "Configuration saved in D:/models/ned\\checkpoint-3800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-3800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-3800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-3800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-4000\n",
      "Configuration saved in D:/models/ned\\checkpoint-4000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-4000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-4200\n",
      "Configuration saved in D:/models/ned\\checkpoint-4200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-4200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-4200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-4200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-4400\n",
      "Configuration saved in D:/models/ned\\checkpoint-4400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-4400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-4400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-4400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-4600\n",
      "Configuration saved in D:/models/ned\\checkpoint-4600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-4600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-4600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-4600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-4800\n",
      "Configuration saved in D:/models/ned\\checkpoint-4800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-4800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-4800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-4800\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-5000\n",
      "Configuration saved in D:/models/ned\\checkpoint-5000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-5200\n",
      "Configuration saved in D:/models/ned\\checkpoint-5200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-5200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-5200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-5200\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer 10.\n",
      "Training layer 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/models/ned\\checkpoint-5400\n",
      "Configuration saved in D:/models/ned\\checkpoint-5400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-5400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-5400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-5400\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-5600\n",
      "Configuration saved in D:/models/ned\\checkpoint-5600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-5600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-5600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-5600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-5800\n",
      "Configuration saved in D:/models/ned\\checkpoint-5800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-5800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-5800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-5800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-6000\n",
      "Configuration saved in D:/models/ned\\checkpoint-6000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-6200\n",
      "Configuration saved in D:/models/ned\\checkpoint-6200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-6200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-6200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-6200\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-6400\n",
      "Configuration saved in D:/models/ned\\checkpoint-6400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-6400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-6400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-6400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-6600\n",
      "Configuration saved in D:/models/ned\\checkpoint-6600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-6600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-6600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-6600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-6800\n",
      "Configuration saved in D:/models/ned\\checkpoint-6800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-6800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-6800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-6800\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-7000\n",
      "Configuration saved in D:/models/ned\\checkpoint-7000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-7200\n",
      "Configuration saved in D:/models/ned\\checkpoint-7200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-7200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-7200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-7200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-7400\n",
      "Configuration saved in D:/models/ned\\checkpoint-7400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-7400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-7400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-7400\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer 9.\n",
      "Training layer 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/models/ned\\checkpoint-7600\n",
      "Configuration saved in D:/models/ned\\checkpoint-7600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-7600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-7600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-7600\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-7800\n",
      "Configuration saved in D:/models/ned\\checkpoint-7800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-7800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-7800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-7800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-8000\n",
      "Configuration saved in D:/models/ned\\checkpoint-8000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-8200\n",
      "Configuration saved in D:/models/ned\\checkpoint-8200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-8200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-8200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-8200\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-8400\n",
      "Configuration saved in D:/models/ned\\checkpoint-8400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-8400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-8400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-8400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-8600\n",
      "Configuration saved in D:/models/ned\\checkpoint-8600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-8600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-8600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-8600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-8800\n",
      "Configuration saved in D:/models/ned\\checkpoint-8800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-8800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-8800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-8800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-9000\n",
      "Configuration saved in D:/models/ned\\checkpoint-9000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-9000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-9200\n",
      "Configuration saved in D:/models/ned\\checkpoint-9200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-9200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-9200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-9200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-9400\n",
      "Configuration saved in D:/models/ned\\checkpoint-9400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-9400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-9400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-9400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-9600\n",
      "Configuration saved in D:/models/ned\\checkpoint-9600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-9600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-9600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-9600\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-9800\n",
      "Configuration saved in D:/models/ned\\checkpoint-9800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-9800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-9800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-9800\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer 8.\n",
      "Training layer 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/models/ned\\checkpoint-10000\n",
      "Configuration saved in D:/models/ned\\checkpoint-10000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-10200\n",
      "Configuration saved in D:/models/ned\\checkpoint-10200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-10200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-10200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-10200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-10400\n",
      "Configuration saved in D:/models/ned\\checkpoint-10400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-10400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-10400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-10400\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-10600\n",
      "Configuration saved in D:/models/ned\\checkpoint-10600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-10600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-10600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-10600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-10800\n",
      "Configuration saved in D:/models/ned\\checkpoint-10800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-10800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-10800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-10800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-11000\n",
      "Configuration saved in D:/models/ned\\checkpoint-11000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-11000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-11200\n",
      "Configuration saved in D:/models/ned\\checkpoint-11200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-11200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-11200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-11200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-11400\n",
      "Configuration saved in D:/models/ned\\checkpoint-11400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-11400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-11400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-11400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-11600\n",
      "Configuration saved in D:/models/ned\\checkpoint-11600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-11600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-11600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-11600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-11800\n",
      "Configuration saved in D:/models/ned\\checkpoint-11800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-11800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-11800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-11800\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-12000\n",
      "Configuration saved in D:/models/ned\\checkpoint-12000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-12200\n",
      "Configuration saved in D:/models/ned\\checkpoint-12200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-12200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-12200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-12200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-12400\n",
      "Configuration saved in D:/models/ned\\checkpoint-12400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-12400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-12400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-12400\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-12600\n",
      "Configuration saved in D:/models/ned\\checkpoint-12600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-12600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-12600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-12600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-12800\n",
      "Configuration saved in D:/models/ned\\checkpoint-12800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-12800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-12800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-12800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-13000\n",
      "Configuration saved in D:/models/ned\\checkpoint-13000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-13000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-13200\n",
      "Configuration saved in D:/models/ned\\checkpoint-13200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-13200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-13200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-13200\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-13400\n",
      "Configuration saved in D:/models/ned\\checkpoint-13400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-13400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-13400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-13400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-13600\n",
      "Configuration saved in D:/models/ned\\checkpoint-13600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-13600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-13600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-13600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-13800\n",
      "Configuration saved in D:/models/ned\\checkpoint-13800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-13800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-13800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-13800\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-14000\n",
      "Configuration saved in D:/models/ned\\checkpoint-14000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-14200\n",
      "Configuration saved in D:/models/ned\\checkpoint-14200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-14200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-14200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-14200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-14400\n",
      "Configuration saved in D:/models/ned\\checkpoint-14400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-14400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-14400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-14400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-14600\n",
      "Configuration saved in D:/models/ned\\checkpoint-14600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-14600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-14600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-14600\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-14800\n",
      "Configuration saved in D:/models/ned\\checkpoint-14800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-14800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-14800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-14800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-15000\n",
      "Configuration saved in D:/models/ned\\checkpoint-15000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-15200\n",
      "Configuration saved in D:/models/ned\\checkpoint-15200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-15200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-15200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-15200\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-15400\n",
      "Configuration saved in D:/models/ned\\checkpoint-15400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-15400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-15400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-15400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-15600\n",
      "Configuration saved in D:/models/ned\\checkpoint-15600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-15600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-15600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-15600\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-15800\n",
      "Configuration saved in D:/models/ned\\checkpoint-15800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-15800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-15800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-15800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-16000\n",
      "Configuration saved in D:/models/ned\\checkpoint-16000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-16000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-16200\n",
      "Configuration saved in D:/models/ned\\checkpoint-16200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-16200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-16200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-16200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-16400\n",
      "Configuration saved in D:/models/ned\\checkpoint-16400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-16400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-16400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-16400\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-16600\n",
      "Configuration saved in D:/models/ned\\checkpoint-16600\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-16600\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-16600\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-16600\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-16800\n",
      "Configuration saved in D:/models/ned\\checkpoint-16800\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-16800\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-16800\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-16800\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-17000\n",
      "Configuration saved in D:/models/ned\\checkpoint-17000\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-17200\n",
      "Configuration saved in D:/models/ned\\checkpoint-17200\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-17200\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-17200\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-17200\\special_tokens_map.json\n",
      "Saving model checkpoint to D:/models/ned\\checkpoint-17400\n",
      "Configuration saved in D:/models/ned\\checkpoint-17400\\config.json\n",
      "Model weights saved in D:/models/ned\\checkpoint-17400\\pytorch_model.bin\n",
      "tokenizer config file saved in D:/models/ned\\checkpoint-17400\\tokenizer_config.json\n",
      "Special tokens file saved in D:/models/ned\\checkpoint-17400\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: lemmas, tokens, ner, orth.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4323\n",
      "  Batch size = 40\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=17450, training_loss=0.11620779499283493, metrics={'train_runtime': 4878.3056, 'train_samples_per_second': 71.536, 'train_steps_per_second': 3.577, 'total_flos': 1.108358648736525e+16, 'train_loss': 0.11620779499283493, 'epoch': 25.0})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Let's evaluate fine-tuned model on"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Re-loading dataset tokenizer and imports."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset kpwrner (D:/cache/huggingface\\clarin-pl___kpwrner\\default\\0.0.0\\001e3d471298007e8412e3a6ccc06bec000dec1bce0cf8e0ba7e5b7e105b1342)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd68a157d1c34e9fbf87136721612b94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at D:/cache/huggingface\\clarin-pl___kpwrner\\default\\0.0.0\\001e3d471298007e8412e3a6ccc06bec000dec1bce0cf8e0ba7e5b7e105b1342\\cache-70c2f2ddf1b4e5e6.arrow\n",
      "Loading cached processed dataset at D:/cache/huggingface\\clarin-pl___kpwrner\\default\\0.0.0\\001e3d471298007e8412e3a6ccc06bec000dec1bce0cf8e0ba7e5b7e105b1342\\cache-654642d003d6e704.arrow\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DataCollatorForTokenClassification,BertForTokenClassification, HerbertTokenizerFast\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "save_path = 'D:/models/ned/checkpoint-15800'\n",
    "cache_dir = 'D:/cache/huggingface'\n",
    "name = \"allegro/herbert-base-cased\"\n",
    "\n",
    "kpwr_set = load_dataset(\"clarin-pl/kpwr-ner\", cache_dir=cache_dir)\n",
    "\n",
    "tokenizer = HerbertTokenizerFast.from_pretrained(\n",
    "    save_path\n",
    ")\n",
    "# Casting NER to NED format\n",
    "def cast_ner_to_ned(tag_i):\n",
    "    tag = kpwr_set['train'].features['ner'].feature.int2str(tag_i)\n",
    "    if 'b' == tag[0].lower():\n",
    "        return 1\n",
    "    if 'i' == tag[0].lower():\n",
    "        return 2\n",
    "\n",
    "    assert tag.lower() == 'o'\n",
    "    return 0\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner\"]):\n",
    "        # Map tokens to their respective word.\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # Only label the first token of a given word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(cast_ner_to_ned(label[word_idx]))\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_kwpr = kpwr_set.map(tokenize_and_align_labels, batched=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model: BertForTokenClassification = BertForTokenClassification.from_pretrained(save_path)\n",
    "test_set = tokenized_kwpr['test']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W końcu wyszło , do czego potrzebne było Google Gears .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']\n",
      "\n",
      "\n",
      "Dorzucono kilka bardziej smakowitych kąsków i mamy wreszcie system operacyjny przeglądarkę Google Chrome .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']\n",
      "\n",
      "\n",
      "Niezależnie od tego , czy będzie to śmiertelny cios dla Windows czy dla Firefoksa , program jest kolejnym zwiastunem zmian w interfejsie graficznym .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Po kilku minutach rzeczywiście da się odczuć szybkość wczytywania stron z JavaScriptem , a każda zakładka w oddzielnym procesie też brzmi nieźle ( szczególnie pod Linuksem * , w którym Adobe Flash regularnie wywala przeglądarki - niestety wersji dla Linuksa na razie brak ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Beznadziejnie na pierwszy rzut oka wyglądają zakładki ( foldery ? ! ) , ale być może trzymanie zakładek w przeglądarce jest już niemodne .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Swoją drogą integracji z del.icio.us też nie widać .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Motywacje Google też są raczej jasne ( konwergencja , znowu ) - gdy Chrome ustawimy jako domyślną przeglądarkę w Windows , nazwa \" Internet \" w menu start nabierze właściwego znaczenia . . .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Chrome wygląda ładnie .\n",
      "True tags:\n",
      "['B', 'I', 'I', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "W nowym Firefoksie jest AwesomeBar , podobny pasek adresu jest też w Chrome .\n",
      "True tags:\n",
      "['O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O']\n",
      "\n",
      "\n",
      "Niby to nic wielkiego - użytkownicy Apple od dawna mają Spotlight ( zresztą - to co w Windowsie nazywa się \" Explorer \" , na Maku od dawna nazywa się \" Finder \" ) , w Viście też jest nieśmiałe okienko wyszukiwania ( choć prezentacja wyników w postaci nudnej listy ) , Google Desktop istnieje już długo , a w Linuksie głowa wręcz boli od przybytku ( Tracker , Beagle , Deskbar ) , ale jedno jest pewne : rola pisania w interfejsie graficznym się zwiększa .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'B', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Jeśli AwesomeBar jest za mało Awesome - można zainstalować Ubiquity .\n",
      "True tags:\n",
      "['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O']\n",
      "\n",
      "\n",
      "Jeśli tekstowa obsługa przeglądarki to za mało - na Maku jest Quicksilver , w Linuksie Gnome Do ( w Windowsie na pewno też coś jest ) : piszesz i wybierasz z listy , program zapamiętuje zachowania użytkownika , czasem wystarczy kilka liter .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Szukanie nie służy już tylko znalezieniu rzeczy , które gdzieś się zapodziały , szukanie zastępuje przeglądanie .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Przecież przed pojawieniem się Google , internet był katalogowany , dopiero później został tak naprawdę zindeksowany .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Być może to stara forma internetu była przyczyną porażki microsoftowego Active Desktop .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']\n",
      "\n",
      "\n",
      "W końcu kiepskie wykonanie , wymuszanie niestandardowych formatów i zasobożerność innym produktom MS nie zaszkodziły . . .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Tymczasem teraz nasze dyski są już zindeksowane , czas wyrobić odpowiednie nawyki .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "A wtedy granica między online i offline zatrze się jeszcze bardziej .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "I kto na tym skorzysta ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "* Firma Google zapisuje Twój adres w celu przesyłania wiadomości dotyczących przeglądarki Google Chrome oraz inforlinuxji o aktualizacjach i wydaniu gotowej wersji .\n",
      "True tags:\n",
      "['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Podanie adresu oznacza wyrażenie zgody na otrzymywanie e - maili zawierających inforlinuxje tego typu .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Google będzie przechowywać Twój adres e - mail przez pewien czas po wydaniu przeglądarki Google Chrome dla systemu Linux , a następnie go usunie .\n",
      "True tags:\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'B', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Więcej inforlinuxji na temat przechowywania danych użytkowników przez Google można znaleźć w zasadach ochrony prywatności .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Subiektywny przegląd kaw z mlekiem i rogalików .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Rogalik spłaszczony przez toster , cukier z wierzchu lekko przypalony , w stylu crema catalana .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ciepły , podany ze sztućcami .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Pocięty w paski .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Rogalik pocięty w paski , na zimno .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Podany ze sztućcami .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Zjadany w centrum przed wyjazdem autobusu na plażę .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Rogalik zwykły i wymiętoszony , do ręki w serwetce , kawa w szczycie długiej przerwy podana w plastikowym kubku .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ale za to cały zestaw za marne 1 euro .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "\n",
      "Stołówka uniwersytecka przerabia kawę i rogaliki w tempie kawiarni na dużym dworcu .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Kawa z mlekiem ciepłym lub zimnym , cortado ( mało mleka ) , cortado z mlekiem skondensowanym ( ale naprawdę skondensowanym , cortado podaje się w małych szklaneczkach , na dnie gruba warstwa mleka , trzeba energicznie wymieszać ) , kawa ( czyli solo , czyli espresso ) . . .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wszystko po pięćdziesiąt centów .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'B', 'B', 'O']\n",
      "\n",
      "\n",
      "Inna uniwersytecka stołówka , 100 metrów dalej , ale ze stolikami na dworze .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ceny zupełnie inne - kawa z mlekiem i rogalik za 1 , 45 euro , różne ceny na różne rodzaje kaw .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ale siedzenie na słońcu , w grudniu - bezcenne .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "I jeszcze środek niedzieli - Alek Tarkowski zwrócił uwagę na przejmowanie przez banki przestrzeni publicznej w Warszawie .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "\n",
      "W niedzielę , około godziny 14 zachciało nam się wyjść na kawę , a dzielnica jest dopiero w budowie ( ma łączyć wybudowany w szczerym polu uniwersytet oraz miasto ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Na rondzie przy głównym wjeździe na teren uniwersytetu są dwa banki .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Na ulicy , która będzie prowadzić do miasta , są jeszcze dwa , mimo że nie da się nią na razie jeździć .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ale kawę ( bez rogalika ) udało nam się znaleźć w jednym z dziewięciu barów , które znajdują się promieniu 500 metrów od mieszkania ( większość była zamknięta , bo niedziela / sjesta , jeden nam się nie podobał itp . ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wszystkie budynki ( z których znaczna część nie jest zamieszkana ) mają przeznaczone miejsce na usługi / sklepy , więc można się spodziewać , że za rok będzie już można wybierać spośród 20 barów , rogalików na ciepło i na zimno , rogalików pociętych w paseczki . . .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Koniec napisów .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Już od dawna trwała walka z amatorami tworzącymi napisy do filmów , teraz skończył się czas polemik w gazecie , pora na salę sądową .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Oczywiście to tylko jedno źródło napisów , ale \" sprawa jest rozwojowa \" .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Łatwiej będzie zapewne nauczyć się angielskiego , niemieckiego , francuskiego , hiszpańskiego , włoskiego , japońskiego i czeskiego ( na początek powinno wystarczyć ) niż zmienić prawo autorskie .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Tymczasem ze wszystkich ogniw \" pirackiego \" łańcucha tłumacze napisów są pewnie najmniej groźni , ale za to najłatwiejsi do wyśledzenia .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "I jak zabierze się napisy , na pewno spadnie liczba ściąganych i udostępnianych filmów .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Na pewno .\n",
      "True tags:\n",
      "['O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O']\n",
      "\n",
      "\n",
      "W okolicy obowiązkowo jest grób Hamleta , wiatraki , a domy kryte są strzechą lub azbestem .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Każdy nosi ze sobą termos , z prohibicją ma on jednak niewiele wspólnego , w środku jest kawa , bez której przeciętny Duńczyk nie przetrwał by nawet godziny .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Kawa jest smolista , raczej przyzwoita i jak na polskie standardy raczej mocna , chociaż fani espresso mogą poczuć się obrażeni takim stwierdzeniem .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Kawę podaje się przy każdej okazji , również w porze na kawę ( o 15 ) , do kawy są wówczas bułki z serem żółtym i marmoladą , ewentualnie ciasto .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Mleka do kawy się nie dolewa , w końcu jest w serze .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ser to tylko jeden element deja vu , które napadło mnie w Danii , gdzie zaczął em czytać nazwy zgodnie z wymową holenderską .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Kawa zresztą też podobna , wioski też jak z Might and Magic , szosy pełne opli astra i fordów focusów , nawet ziołowa wódka taka sama .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "I oczywiście ser z kminkiem .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Goudse belegen met komijn był zawsze moim holenderskim faworytem , w Danii sery również występują w różnym stopniu dojrzałości , a dojrzały danbo . . .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wystarczy uchylić lodówkę , żeby wiedzieć , że został jeszcze kawałek .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Szkoda , że taki mały .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "W Danii trafił em akurat na ekspresowe żniwa , cały lipiec padało , musieli nadrabiać .\n",
      "True tags:\n",
      "['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Patrząc na gigantyczne traktory i imperialne kombajny trudno zrozumieć duński dystans wobec Unii Europejskiej .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'I', 'O']\n",
      "\n",
      "\n",
      "Chociaż rozmawiał em z młodym rolnikiem , który ma dwadzieścia hektarów , biegle mówi po angielsku i na wakacje jeździ do Austrii na narty .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Uprawia ziemię , bo lubi , uważa to za ciekawą pracę i nie ma nic do UE .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "\n",
      "Zresztą duńscy rolnicy , nie tylko młodzi , wyposażeni są w komputery i stałe łącza , na dodatek potrafią z nich korzystać .\n",
      "True tags:\n",
      "['O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Mają swoje strony internetowe , wprawdzie na etapie 1 . 0 , nikt mnie do facebooka nie zaprosił , ale sieciowe umiejętności są tam nieporównywalnie większe niż w Polsce .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'I', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "\n",
      "Poza tym Dania to spokojne wakacje ( jeśli zignorujemy to , że nasz domek wakacyjny może być pokryty azbestem ) , był em w szczycie sezonu , w weekend , pogoda momentami niezła , a plaże i deptaki niemal puste .\n",
      "True tags:\n",
      "['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "We wszystkich wioskach osiedla domków letniskowych , kemping co dwa kilometry , ale znikąd nie dobiega basowe dudnienie , może był em na zbyt głębokiej prowincji , a może rozrywkowi Niemcy , Duńczycy i Holendrzy jeżdżą raczej do Hiszpanii .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'B', 'O', 'B', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "\n",
      "Morza szum ( w końcu był em nad Bałtykiem ) , tłuste jedzenie - bo oprócz serów występuje sporo mięsa , kotletów mielonych w różnych postaciach , boczku w grubych plastrach , piwo , które niegdyś sprowadzało się do dwóch różnych marek ( w tym tego w prawdopodobnie najlepszej butelce ) , a teraz rzekomo co tydzień powstaje ( wskrzesza się ? ) nowy lokalny browar , chociaż trzeba uważać , bo ceny lokalnych specjałów raczej nie dla nas , chyba że w przeliczeniu na procenty , bo wtedy niektórym piwom bliżej zdecydowanie do wina , a smak bynajmniej nie przypomina polskich \" mocnych \" i powiewające wszędzie , przed domami , za domami i obok domów , duńskie flagi .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Czy piosenka to samochód ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Problem , czy chronić informacje jak własność materialną nie jest nowy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Dla amerykańskiego prawnika , który przerabia ekonomiczną analizę prawa na studiach , to oczywistość .\n",
      "True tags:\n",
      "['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Polski prawnik na studiach miał może wprowadzenie do mikro i makro , więc przy odrobinie szczęścia odróżni inflację od elastyczności popytu .\n",
      "True tags:\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "W związku z tym w Polsce można zawsze liczyć na to , że prawnik ZAiKSu powie , że przecież to oczywiste , że samochód i zdjęcie to jest dokładnie to samo .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Bo przyszedł do niego zapłakany fotograf .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Bo gdyby chciał wejść do czyjegoś samochodu , to musiał by zapytać o zgodę .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Musiał by zapytać o zgodę właściciela ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "A dlaczego samochód ma właściciela ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Dlaczego o zgodę , oprócz użytkownika , nie trzeba pytać więc producenta samochodu ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Albo koproducentów , producenta klamki , tapicerki ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Oczywiście , szybko można znaleźć wyjątki .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Samochód wypożyczony albo samochód w leasingu być może jest bardziej podobny do utworu , którego licencję kupujemy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Jest jednak pewna zasadnicza różnica , jak powiedział Krzysztof Siewicz - nie ma zaczarowanego ołówka , którym możemy ten wypożyczony samochód sobie skopiować .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wciąż jeden samochód w tym samym czasie może pokonać jedną trasę , zmieści się w nim określona liczba osób .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Dlaczego producenci nie chcieli by zmienić modelu sprzedaży samochodów ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Może powinni zacząć lobbować za takim rozwiązaniem ( oczywiście , jak już uda im się wylobbować ratunek przed kryzysem ) , bo przecież nie ma nic lepszego niż własność dla producenta i ustawowo ograniczone prawa nabywców .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Dlaczego nie wprowadzić licencji na samochody zamiast własności ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Albo licencji na wszystko ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Niech tylko pierwotny twórca - stolarz , murarz , ślusarz będzie właścicielem , a użytkownik licencjobiorcą .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "A jeśli produkcja jest bardziej skomplikowana ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Nic prostszego - można wprowadzić takie prawo , żeby współproducentom również przysługiwało wynagrodzenie .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Jak tego pilnować ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Czy na pewno nabywca krzesła nie korzysta z niego na imprezie publicznej ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Może na imprezę przyszedł ktoś spoza kręgu towarzyskiego ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Czy licencja obejmuje przewożenie autostopowiczów ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Można powołać odpowiednią organizację , albo lepiej 1000 organizacji , które będą to sprawdzać i liczyć , a następnie rozdzielać należne tantiemy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wtedy wszyscy wreszcie staniemy się rentierami .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Czeczenia , nazwa która często przewija się w gazetach i telewizji , szaremu obywatelowi mówi niewiele .\n",
      "True tags:\n",
      "['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Większość Polaków nawet nie wie gdzie ten kraj leży i dlaczego walczy z Rosją .\n",
      "True tags:\n",
      "['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "\n",
      "Chciał by m choć trochę przybliżyć problematykę Kaukazu i napięć w tamtejszych republikach .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Kiedy 11 marca 1985 roku Biuro Polityczne KC KPZR powierzyło obowiązki Sekretarza Generalnego KC PZPR Michaiłowi Gorbaczowowi nikt na Kaukazie nie zdawał sobie sprawy , że nadchodzi czas zmian .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'O', 'O', 'O', 'B', 'O', 'I', 'B', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Gorbaczow starający się uratować gospodarkę a także odnowić zmurszały aparat partyjny wprowadził głasnost i pierestrojkę co jednak przyczyniło się do aktywizacji środowisk demokratycznych i wywołało falę separatyzmów i zadawnionych antagonizmów nie tylko na Kaukazie .\n",
      "True tags:\n",
      "['B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O']\n",
      "\n",
      "\n",
      "Naród czeczeński , prześladowany za dążenie do niepodległości poczuł wiatr zmian w październiku 1987 roku , kiedy nieliczna grupa intelektualistów powołała przy Komsomole w Groznym – Stowarzyszenie „ Kaukaz ” mające początkowo formę forum dyskusyjnego .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Powodem powstania i aktywizacji działaczy czeczeńskich było poparcie dla reform Gorbaczowa a także dążenie do wolności słowa , wyjaśnienia tragicznej historii narodu czeczeńskiego , odnowy kultur a także rozwiązania problemów narodowościowych w republice .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "W 1988 roku ukształtował się Związek Poparcia Pierestrojki , organizacja posiadająca nieformalne poparcie Moskwy ( stąd nazywani często „ nieformałami ” ) organizująca wiece w Groznym pod hasłem sprawiedliwości społecznej .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Postępująca jednak radykalizacja stanowiska Związku zaniepokoiło Moskwę , która zakazała organizowania wieców .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wiece „ nieformałow ” stały się jednak stałym elementem życia publicznego Groznego , aktywizując stopniowo cały kraj .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Późnym latem 1988 roku wraz z przekształceniem się Związku we Front Ludowy Cz-I ASRR pojawiły się żądania zmian we władzach republiki , co nastąpiło wiosną 1989 roku .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "I Sekretarzem został Doku Zawgajew , pierwszy Czeczen na tym stanowisku w historii co wywołało falę entuzjazmu .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wraz z wstąpieniem Zawgajewa na stanowisku Sekretarza nastąpiła liberalizacja życia republiki , która w lutym i marcu 1990 roku doprowadziła do wykształcenia się dwóch obozów : konserwatywno - internacjonalistycznego zdominowanego przez Rosjan i nurt partyjnych liberałów opowiadających się za pełną autonomią i możliwością wyjścia z ZSRR .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O']\n",
      "\n",
      "\n",
      "Ogromną rolę w życiu Czeczenów odgrywa islam .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Za rządów Zawgajewa udało się utworzyć Czeczeno - Inguski Muzułmański Zarząd Duchowny , którego zadaniem była odbudowa świadomości muzułmańskiej .\n",
      "True tags:\n",
      "['O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "W marcu 1990 r . odbyły się wybory deputowanych ludowych RFSRR i Cz-I ASRR .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'O']\n",
      "\n",
      "\n",
      "W Radzie znalazła się stosunkowo silna grupa opozycyjnych działaczy , którzy utworzyli frakcję pod nazwą Inicjatywa Demokratyczna .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']\n",
      "\n",
      "\n",
      "Przewodniczącym Rady został wybrany Zawgajew , co pozwoliło na kontynuowanie liberalizacji życia publicznego .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Choć zazwyczaj jestem bardzo ostrożna i nie klikam we wszystko co popadnie , tym razem nie zachowała m czujności rewolucyjnej – kliknęła m w URL z wiadomości odruchowo i bez zastanowienia .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "I tylko dzięki Firefoxowi nie weszła m na stronę , która usiłowała się otworzyć .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Przeglądarka zidentyfikowała stronę jako niebezpieczną .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Sprawdziła m dokładniej adres pod linkiem – ukryto w nim fragment – secure-myspace.com/redirect.htm?blog.myspace.com/ .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Poza podejrzanym przekierowaniem autentyczny adres nie zawiera myślnika tylko kropkę ( secure.myspace.com ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Z ciekawości odwiedziła m kilka profili użytkowników MySpace i w wielu komentarzach znalazła m podobną wiadomość wysłaną z kont różnych użytkowników .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Przypuszczam , że cała ta akcja działa na zasadzie łańcuszka ( tak , jak wiele „ robali ” mailowych ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Jeśli ktoś otworzy stronę podaną w linku hakerzy uzyskują dostęp do jego konta i z niego rozsyłają fałszywe komentarze do wszystkich przyjaciół .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Moja wiedza na temat hakowania jest zerowa ( i nie odczuwam potrzeby szkolenia się w tej dziedzinie ) zatem być może się mylę .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "W każdym razie użytkownikom MySpace radzę bardzo uważać na to w co klikają ( choć pewnie większość nie klika mechanicznie ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "\" zamiast edukować użytkowników internetu , przyjęto strategię siania niepokoju i niszczenia konkurencji \" - na pewno nie ma żadnych tekstów edukujących ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "To są insynuacje .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "\" oczywiście , jak każda służba , giodo będzie chciało się wykazać \" - rzeczywiście po ostatnich dwóch latach można odnieść wrażenie , że służby powołano wyłącznie w celu wykazywania się , ale gdzie te liczne przykłady nadużyć GIODO ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O']\n",
      "\n",
      "\n",
      "\" ogólne przekaz jest prosty : \" - typowa łasica .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "\" brakuje tylko płaczącego dziecka i mieli by śmy gazetową wersję programu redaktor jaworowicz \" - jednak płaczącego dziecka brakuje .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Sytuacji nie ratuje tu ani forma wypowiedzi ( felieton ) , ani miejsce ( blog ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Jeśli oskarżasz kogoś o sianie zamętu , zbierasz burzę .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Sam fakt , że nie wiesz , czy Agora rzeczywiście kazała swoim redaktorom napadać na Naszą Klasę w ramach nieczystej walki rynkowej , ale to sugerujesz , a potem na Twój autorytet powołuje się Dziennik , żeby rzeczywiście Agorze dokopać ( co oczywiście nie było Twoim zamiarem , a Dziennik olał prawo , o dobrych obyczajach nie wspominając ) , jest czarnym PR , może rzeczywiście bardziej niż FUDem , ale metoda jest podobna .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Informacje są negatywne , są ogólne i mają zdyskredytować konkretny podmiot w konkretnym przypadku .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Masz oczywiście rację , że Wyborcza przesadziła , że wyszedł im FUD , nawet jeżeli wynikał z głupoty redaktorów , którzy o internecie nie wiedzą nic , a ochronie danych osobowych jeszcze mniej .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Głupota ich nie usprawiedliwia .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Kontrola zbiorów danych jest jednak najważniejszym zadaniem GIODO , do tego cały ten urząd został powołany .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Odbędzie się nie dlatego , że Wyborcza napisała o przerażonej prawniczce , tylko Wyborcza napisała o przerażonej prawniczce ( podkreślam ponownie , że głupio napisała ) , bo odbędzie się kontrola .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Od razu zaznaczę , że filmu nie widział em i chyba nie planuję , bo jestem podatny na sugestie , a paleniu podziękował em kilka lat temu .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Nie interesuje mnie to , czy ludzie zaczynają palić wyłącznie w wyniku działania wolnej woli , presji otoczenia , spisku wielkich korporacji , reklam z sympatycznym wielbłądem czy nadmiaru wyścigów Formuły 1 obejrzanych w młodości .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Załóżmy , że jest to ich wolny wybór .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Palenie jednak produkuje znaczne negatywne efekty zewnętrzne - w postaci kosztów opieki zdrowotnej ( efekt gapowicza - skoro wszyscy płacą tyle samo , to ja mogę pogorszyć swoje zdrowie bardziej od innych ) , śmieci i pogorszenia się samopoczucia osób niepalących - i w związku z tym wolność palacza wchodzi w konflikt z wolnością niepalacza .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Przesuwanie tych granic jest takim samym zamachem na wolność palaczy , jak ustalenie ich na dotychczasowym poziomie było zamachem na wolność niepalaczy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Próby rozwiązania problemu efektów zewnętrznych obejmują działania z zakresu prawa ( ustawowe zakazy ) , rynku ( wysoka cena papierosów ) i może architektury ( o ile brak popielniczki może kogoś zniechęcić ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "A normy społeczne zakładają tolerancję ( przypominam sobie taki fragment jakiegoś tekstu o savoir vivre , chyba nawet w poważnej gazecie , choć nie można wykluczyć , że zebrało mi się kiedyś na czytanie kolorowego opakowania do płyty DVD , brzmiący mniej więcej tak \" jeśli Twoi goście palą , musisz niestety pozwolić im palić w salonie \" ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "To już mniejsza tolerancja spotyka miłośników czosnku na śniadanie .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "O pierdzeniu przy stole nie wspominając .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Na szczęście Blogger umożliwia dodawanie wpisów zaplanowanych , czyli można dosłownie \" pisać \" o punkt 12 . 00 w Nowy Rok : o ) Ja nie należę do ludzi którzy wszędzie biegają z komputerem albo komórką z internetem w środku , ale wystarczająco takich znam , więc przesyłam życzenia w ten sposób : ) Mam nadzieję że będę mogła więcej blogować , ale patrząc na moje życie teraz to nie wiem w ogóle co , gdzie i w którąż stronę .\n",
      "True tags:\n",
      "['O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Możliwe że się będziemy przeprowadzać i w ogóle nic nie wiadomo : p Ale co tam .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Po to właśnie mam mój blog , aby mieć takie spokojne i całkiem prywatne i własne miejsce na świecie .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wszystko jedno gdzie nas los przerzuci . .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Artykuły archiwalne , publikowane podczas pierwszych prób tworzenia Obiektywu.net .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O']\n",
      "\n",
      "\n",
      "U progu ubóstwa\n",
      "True tags:\n",
      "['O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O']\n",
      "\n",
      "\n",
      "Konserwatyzm jako postawa życiowa i ideowa\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ludzkość wkroczyła w XXI wiek .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Pełna obaw o przyszłość , ale ufna … nauczona tragicznością swej historii , ale wciąż jeszcze nie potrafiąca jednoznacznie się od niej odciąć …\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ludzkość dążąca do równowagi … ludzkość , która choć poradziła sobie z większością reżimów politycznych wciąż jeszcze uwięziona w totalitaryzmie własnego zła i własnej ułomności nie może otwarcie pędzić ku pełnemu wyzwoleniu …\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "W takich czasach po raz kolejny powraca pytanie o ideę , która pozwoliła by lepiej ustosunkować się do rzeczywistości , po raz kolejny ścierają się postawy i światopoglądy dające ludziom , jeśli nie praktyczne , to choćby teoretyczne podstawy do określenia ich własnego miejsca na świecie …\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Człowiek , będąc w większości przypadków istotą rozumną , od zarania dziejów dążył do uproszczenia wszelkich czynności z jakimi borykał się podczas swojej egzystencji oraz do zwiększenia wydajności wykonywanej przez siebie pracy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ten tok myślenia przez całe tysiąclecia owocował nowymi wynalazkami , wzrostem wydajności i opłacalności produkcji , oraz skróceniem czasu pracy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ale to , co wydawało się błogosławieństwem dla rozwoju ludzkości , powoli zaczęło stawać się zmorą każdego zatrudnionego w fabryce robotnika i rzemieślnika .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wynalezienie pierwszego zdolnego do pracy parowego silnika tłokowego ( W . Brytania , pocz . XVIII w . ) przyspieszyło rozwój budowy maszyn produkcyjnych , a tym samym spowodowało zmniejszenie ilości etatów , wymaganych do wytworzenia produktu finalnego , jak też do prowadzenia i funkcjonowania przedsiębiorstw .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wynalezienie silnika spalinowego i elektrycznego tylko pogłębiło ten proces .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Maszyny wygrywały z ludźmi walkę o zatrudnienie , gdyż pracowały bardziej niezawodnie , stale i z większą precyzją .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Pojawiło się zatem na ogromną skalę zjawisko znane nam dziś jako bezrobocie , a razem z nim niepokoje społeczne ( dające swój wyraz w niszczeniu maszyn ) i nędza niższych warstw społecznych .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Ponieważ pierwsza przeglądarka internetowa stworzona przez Bernersa - Lee była jednocześnie edytorem stron , przypisuje się mu zapoczątkowanie web 2 . 0 , wiki , blogów i w ogóle całego UGC .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O']\n",
      "\n",
      "\n",
      "Wszystko zepsuli więc i opóźnili Marc Andreessen i Eric Bina , autorzy przeglądarki Mosaic , która skupiła się na przeglądaniu , a tworzenie kodu HTML pozostawiła innym przyczyniając się do erozji powagi zawodu informatyka , bo geekiem od HTML mógł zostać każdy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'B', 'B', 'I', 'I', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Gdyby użytkownik od początku miał możliwość jednym programem oglądać i tworzyć sieć , być może nie pojawili by się specjaliści od siedmiu boleści , którzy nie dość , że uważają się za wielkich informatyków , to ich gust ogranicza się do niebieskiego tła , a w wersji 2 . 0 gradientu .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Musiało minąć kilka lat , żeby znaleźli się śmiałkowie , którzy przezwyciężyli fobie i zaczęli używać przeglądarek nie tylko do przeglądania .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Poszukiwanie jajka i kury pozostawiam jednak innym , choć zgadzam się , że Berners - Lee na pewno wyprzedził swoją epokę , a jego pomysł wciąż może się okazać bardziej przełomowy , niż nam się teraz wydaje .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Z różnych notek o blogowaniu przy okazji tych urodzinowych i terminologicznych problemów zwrócił moją uwagę wpis Schwartza , który jest CEO Suna i podąża z duchem czasu i osiągnięciami .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Prowadzi dziwny dziennik marketingowo - technologiczny , który jest ciekawy choćby z takiej przyczyny , że nie wiadomo , czy pan Schwartz wyciągnie Suna z tarapatów ( na razie na to się zanosi ) dzięki różnym modelom biznesowym związanym z wolnym oprogramowaniem , czy wręcz przeciwnie ( wciąż jest to dość prawdopodobne ) .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Otóż Schwartz został poproszony o skomentowanie przypadku innego CEO , który komentował pod pseudonimem .\n",
      "True tags:\n",
      "['O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Schwartz został zakwalifikowany do kategorii blogujących CEO , chociaż nie chciał .\n",
      "True tags:\n",
      "['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Po co więc pisze tego swojego bloga ( jak głosi oficjalna nazwa ) ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Czy każdy , kto coś regularnie pisze w internecie w tym samym miejscu będzie już blogerem ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Czy osoba , która zawsze jako jedna z pierwszych sadzi obszerny komentarz na popularnej stronie bloguje , bo w sumie regularnie i w tym samym miejscu można ją znaleźć ?\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Schwartz w ogóle chciał by usunąć termin \" blogowanie \" , a jeszcze niedawno chciał być \" kropką w web 2 . 0 \" .\n",
      "True tags:\n",
      "['B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'I', 'I', 'I', 'O', 'O']\n",
      "\n",
      "\n",
      "Ale jak przystało na człowieka z kucykiem i w krawacie , blogujący CEO jest pełen sprzeczności .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wiosna wietrzna , ale w końcu biednemu wiatr w oczy .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Biednemu , bo przecież tylko taki , co go nie stać na samochód , musi się zadowolić połową kółek i męczy się na rowerze .\n",
      "True tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Wrocław jest miastem pozornie płaskim , ale wyjątkowo często mam wrażenie , że lepiej było by zainwestować w rower górski .\n",
      "True tags:\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Predicted tags:\n",
      "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m     last_label \u001B[38;5;241m=\u001B[39m label\n\u001B[0;32m     16\u001B[0m x \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mencode_plus(tokens, is_split_into_words\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 17\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m pred_softmaxed \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(pred\u001B[38;5;241m.\u001B[39mlogits[\u001B[38;5;241m0\u001B[39m], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# first let's fix 'I' token predicted before 'B' token\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1725\u001B[0m, in \u001B[0;36mBertForTokenClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1718\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1719\u001B[0m \u001B[38;5;124;03mlabels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\u001B[39;00m\n\u001B[0;32m   1720\u001B[0m \u001B[38;5;124;03m    Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\u001B[39;00m\n\u001B[0;32m   1721\u001B[0m \u001B[38;5;124;03m    1]``.\u001B[39;00m\n\u001B[0;32m   1722\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1723\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1725\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1726\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1727\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1729\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1730\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1731\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1732\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1733\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1734\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1735\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1737\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1739\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(sequence_output)\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:995\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    986\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m    988\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m    989\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m    990\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    993\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m    994\u001B[0m )\n\u001B[1;32m--> 995\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    996\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    997\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    998\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1002\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1004\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1005\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1006\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1007\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1008\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:582\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    573\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    574\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    575\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 582\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    588\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    589\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    592\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    593\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:510\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    507\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    508\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[1;32m--> 510\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    513\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs\n\u001B[0;32m    515\u001B[0m \u001B[38;5;66;03m# if decoder, return the attn key/values as the last output\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\transformers\\modeling_utils.py:2330\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[0;32m   2327\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[0;32m   2328\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[1;32m-> 2330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:523\u001B[0m, in \u001B[0;36mBertLayer.feed_forward_chunk\u001B[1;34m(self, attention_output)\u001B[0m\n\u001B[0;32m    521\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeed_forward_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_output):\n\u001B[0;32m    522\u001B[0m     intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(attention_output)\n\u001B[1;32m--> 523\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mintermediate_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    524\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:438\u001B[0m, in \u001B[0;36mBertOutput.forward\u001B[1;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states, input_tensor):\n\u001B[1;32m--> 438\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    439\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[0;32m    440\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\conda-envs\\hf-download-test-finetune\\lib\\site-packages\\torch\\nn\\functional.py:1848\u001B[0m, in \u001B[0;36mlinear\u001B[1;34m(input, weight, bias)\u001B[0m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[0;32m   1847\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(linear, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, weight, bias\u001B[38;5;241m=\u001B[39mbias)\n\u001B[1;32m-> 1848\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "itos = {0: 'O', 1: 'B', 2: 'I', -100: '-'}\n",
    "counter = 5\n",
    "for example in test_set:\n",
    "    tokens = example['tokens']\n",
    "    labels = example['labels']\n",
    "    true_tags = []\n",
    "    last_label = 0\n",
    "    for label in labels[1:-1]:\n",
    "        if label == -100:\n",
    "            if last_label == 1:\n",
    "                label = 2\n",
    "            else:\n",
    "                label = last_label\n",
    "        true_tags.append(itos[label])\n",
    "        last_label = label\n",
    "    x = tokenizer.encode_plus(tokens, is_split_into_words=True, return_tensors='pt')\n",
    "    pred = model(**x)\n",
    "\n",
    "    pred_softmaxed = torch.nn.functional.softmax(pred.logits[0], dim=-1)\n",
    "    # first let's fix 'I' token predicted before 'B' token\n",
    "    predicted_labels = []\n",
    "    last_label = 0\n",
    "    for i in range(pred_softmaxed.shape[0]):\n",
    "        token_preds = pred_softmaxed[i]\n",
    "        if token_preds.argmax(dim=-1) == 2 and last_label == 0:\n",
    "            token_preds[1] = float('-inf')\n",
    "        new_label = token_preds.argmax(dim=-1).item()\n",
    "        last_label = new_label\n",
    "        predicted_labels.append(itos[new_label])\n",
    "    if counter > 0 or predicted_labels != true_tags:\n",
    "        print(' '.join(tokens))\n",
    "        print(f\"True tags:\\n{true_tags}\\n\")\n",
    "        print(f\"Predicted tags:\\n{predicted_labels[1:-1]}\\n\\n\")\n",
    "        counter -= 1\n",
    "    else:\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    0, 15938,  5637,  2921,  2099,  1026,  1335,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'końcu', 'wyszło', ',', 'do', 'czego', 'potrzebne', 'było', 'Google', 'Gears', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[    0,  1049,  4988, 15283,  1947,  2041,  2784,  7318,  2404, 22532,\n          4281, 41959,  1899,     2]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_set = tokenized_kwpr['test']\n",
    "print(example['tokens'])\n",
    "tokenizer.encode(example['tokens'], is_split_into_words=True, return_tensors='pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}